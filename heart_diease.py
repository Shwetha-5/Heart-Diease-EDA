# -*- coding: utf-8 -*-
"""heart diease

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1npqhA36kt8H-aIar5cX4GexM6eUXtegW
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.metrics import confusion_matrix,classification_report
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('/content/heart_disease_dataset.csv')

df.describe()

df.info()

df.head(5)

#sns.set_style('darkgrid')
plt.figure(figsize = (10, 8))

sns.distplot(df['Age'])

df['Gender'].unique()

female = df['Gender'].value_counts()['Female']
male = df['Gender'].value_counts()['Male']

labels = ['Female', 'Male']
colors = ['pink', 'blue']

values = [female, male]

plt.pie(values, labels = labels, colors = colors, autopct = '%1.2f%%')
plt.title('Gender Distribution')
plt

plt.figure(figsize = (10, 8))
sns.lineplot(data = df, y = 'Cholesterol', x = 'Blood Pressure', color = 'green')

plt.figure(figsize = (10, 8))
sns.barplot(data = df, x = 'Smoking', y = 'Blood Pressure', hue = 'Gender')

sns.lineplot(data = df, x = 'Exercise Hours', y = 'Blood Sugar')

df['Stress Level'].unique()

plt.figure(figsize = (10, 6))
sns.jointplot(data = df, x = 'Stress Level', y = 'Blood Pressure', kind ='kde')

df = pd.get_dummies(df, columns = ['Gender', 'Family History', 'Diabetes', 'Obesity', 'Exercise Induced Angina'], drop_first = True)

df.head()

le = LabelEncoder()
df['Smoking'] = le.fit_transform(df['Smoking'])
df['Alcohol Intake'] = le.fit_transform(df['Alcohol Intake'])
df['Chest Pain Type'] = le.fit_transform(df['Chest Pain Type'])

y = df['Heart Disease']
x = df.drop('Heart Disease', axis = 1)

x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.75, random_state = 42)

rf = RandomForestClassifier()
rf.fit(x_train, y_train)

pred_rf = rf.predict(x_test)
print(classification_report(y_test,pred_rf))

xg_model = xgb.XGBRegressor(n_estimators = 250, max_depth = 6, subsample = 0.75, learning_rate = 0.05)
xg_model.fit(x_train, y_train)

score_xg = xg_model.score(x_test, y_test)
print(f'XGB Regressor Score: {score_xg}')

lr_model = LogisticRegression()
lr_model.fit(x_train, y_train)
pred_lr = lr_model.predict(x_test)
print(classification_report(y_test, pred_lr))

# Accuracy Score for each model
from sklearn.metrics import accuracy_score

acc_rf = accuracy_score(y_test, pred_rf)
acc_lr = accuracy_score(y_test, pred_lr)
acc_xg = score_xg

# Bar plot comparison
plt.figure(figsize=(8, 5))
models = ['Random Forest', 'Logistic Regression', 'XGBoost']
scores = [acc_rf, acc_lr, acc_xg]
plt.bar(models, scores, color=['lightpink', 'lightgreen', 'lightblue'])
plt.title('Model Comparison: Accuracy')
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.show()

# Random Forest Feature Importance
importances_rf = rf.feature_importances_
print(importances_rf)
indices_rf = importances_rf.argsort()

plt.figure(figsize=(10, 6))
plt.title('Random Forest Feature Importance')
plt.barh(range(len(indices_rf)), importances_rf[indices_rf], align='center')
plt.yticks(range(len(indices_rf)), [x_train.columns[i] for i in indices_rf])
plt.xlabel('Relative Importance')
plt.show()

# XGBoost Feature Importance
importances_xg = xg_model.feature_importances_
indices_xg = importances_xg.argsort()

plt.figure(figsize=(10, 6))
plt.title('XGBoost Feature Importance')
plt.barh(range(len(indices_xg)), importances_xg[indices_xg], align='center')
plt.yticks(range(len(indices_xg)), [x_train.columns[i] for i in indices_xg])
plt.xlabel('Relative Importance')
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Random Forest Confusion Matrix
cm_rf = confusion_matrix(y_test, pred_rf)
ConfusionMatrixDisplay(cm_rf, display_labels=['No Disease', 'Disease']).plot(cmap='Blues')
plt.title('Random Forest Confusion Matrix')
plt.show()

# Logistic Regression Confusion Matrix
cm_lr = confusion_matrix(y_test, pred_lr)
ConfusionMatrixDisplay(cm_lr, display_labels=['No Disease', 'Disease']).plot(cmap='Greens')
plt.title('Logistic Regression Confusion Matrix')
plt.show()